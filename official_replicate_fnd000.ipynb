{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "About the Dataset\n",
        "  1. id: unique id for a news article\n",
        "  2. title: the title of a news article\n",
        "  3. author: author of the news article\n",
        "  4. text: the text of the article could be incomplete \n",
        "  5. label: a label that marks whether the news article is real or fake:\n",
        "\n",
        "```\n",
        "  1: fake news\n",
        "  0: real news\n",
        "```\n"
      ],
      "metadata": {
        "id": "LYPj-RmbxNyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing the dependencies "
      ],
      "metadata": {
        "id": "IyPmtulOydGJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhzH3JwfstjL"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import re #regular expression, used for searching words in expressions\n",
        "from nltk.corpus import stopwords #words that dont add much value to paragraphs: eg \"where, what, etc\"\n",
        "# nltk = natural language toolkit, the text we will take to create the natural language\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# stemming takes a wrod and removisn gthe prefix and suffix and gives root word, this comand will do that for us\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# convert text to feature vectors which is bascially just numbers\n",
        "from sklearn.model_selection import train_test_split\n",
        "# split data into training data and test data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first we need to remove stopwards from dataset\n",
        "#then stem all words, to stem words, gives rood words for any words \n",
        "#feature extraction makes words into feature vectors\n",
        "# train_test_split = splitting training and test data"
      ],
      "metadata": {
        "id": "qB2Ec_si0ywl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download stopwards from nltk library\n",
        "import nltk \n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBASMzsD1OWk",
        "outputId": "63a77005-deab-44f9-d5f4-d0dd689e4950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the words that dont add value in english (stopwords)\n",
        "print (stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHVtFRab1iYC",
        "outputId": "523d818c-bffc-45c3-a645-52b53db5e5e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data pre-proessing "
      ],
      "metadata": {
        "id": "PgD6zc3s4R0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading datasets into a pandas Dataframe\n",
        "news_dataset = pd.read_csv('/content/train.csv.zip') #loads our training data to a new variable"
      ],
      "metadata": {
        "id": "s288SUnw4UXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this dataset\n",
        "news_dataset.shape\n",
        "#outcome = 20800 rows and 5 columns. 20800 news article"
      ],
      "metadata": {
        "id": "Th71QasoKVwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7156798f-1cb0-4c7c-da74-e9982ae072e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 rows of dataframe \n",
        "news_dataset.head()\n",
        "#prints data: "
      ],
      "metadata": {
        "id": "cww-3PGVLA2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "efa2691d-765d-4a88-8116-9d38aedc3d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              title              author  \\\n",
              "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
              "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
              "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
              "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
              "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
              "\n",
              "                                                text  label  \n",
              "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
              "1  Ever get the feeling your life circles the rou...      0  \n",
              "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
              "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
              "4  Print \\nAn Iranian woman has been sentenced to...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b274b26-d373-4f39-a352-4c57b2c3efd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b274b26-d373-4f39-a352-4c57b2c3efd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b274b26-d373-4f39-a352-4c57b2c3efd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b274b26-d373-4f39-a352-4c57b2c3efd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of missing data/values in the dataset\n",
        "news_dataset.isnull().sum()\n",
        "#counts missing valuesin each column. insull is the comand. NOTE: always mention dataset first"
      ],
      "metadata": {
        "id": "eHXN0x-sLQiK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ae9381-a888-443c-bfdc-e29db1cdc208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           0\n",
              "title      558\n",
              "author    1957\n",
              "text        39\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if alot of values missing, u do imputation to rplace with proper vlaues, but since our data set is so large, we have enough"
      ],
      "metadata": {
        "id": "5FbJkrLsLdu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replacing the null values with empty string \n",
        "news_dataset = news_dataset.fillna('')"
      ],
      "metadata": {
        "id": "PI4e653KL5bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for our prediction we incide author and title, we want to combine togehter. We dont uet text, just use title and author\n",
        "#you can use text sometimes but title + author can give good accuracy"
      ],
      "metadata": {
        "id": "rGoTHizQMHBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging author name and news title \n",
        "news_dataset['content'] = news_dataset['author']+' '+news_dataset['title']"
      ],
      "metadata": {
        "id": "FaBr3jiPMOOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_dataset['content'])\n",
        "#output would be author name first and then title, so its a new datata (content data to make the predictions)"
      ],
      "metadata": {
        "id": "y8EhEw73MovN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c108dbd1-1505-43f0-9295-de056cbff61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
            "1        Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
            "2        Consortiumnews.com Why the Truth Might Get You...\n",
            "3        Jessica Purkiss 15 Civilians Killed In Single ...\n",
            "4        Howard Portnoy Iranian woman jailed for fictio...\n",
            "                               ...                        \n",
            "20795    Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...\n",
            "20796    Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
            "20797    Michael J. de la Merced and Rachel Abrams Macy...\n",
            "20798    Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
            "20799              David Swanson What Keeps the F-35 Alive\n",
            "Name: content, Length: 20800, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seperating the data & label\n",
        "X = news_dataset.drop(columns= 'label', axis=1)\n",
        "#want to remove lables and store all data without the label \n",
        "  # you need to say axis=1 to remove the column\n",
        "Y = news_dataset['label']"
      ],
      "metadata": {
        "id": "WKUGvNBdMq_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "2kvvL1bCNAKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2de6946-cc3a-4f98-892f-b29cb83d6038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          id                                              title  \\\n",
            "0          0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
            "1          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
            "2          2                  Why the Truth Might Get You Fired   \n",
            "3          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
            "4          4  Iranian woman jailed for fictional unpublished...   \n",
            "...      ...                                                ...   \n",
            "20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
            "20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
            "20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
            "20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
            "20799  20799                          What Keeps the F-35 Alive   \n",
            "\n",
            "                                          author  \\\n",
            "0                                  Darrell Lucus   \n",
            "1                                Daniel J. Flynn   \n",
            "2                             Consortiumnews.com   \n",
            "3                                Jessica Purkiss   \n",
            "4                                 Howard Portnoy   \n",
            "...                                          ...   \n",
            "20795                              Jerome Hudson   \n",
            "20796                           Benjamin Hoffman   \n",
            "20797  Michael J. de la Merced and Rachel Abrams   \n",
            "20798                                Alex Ansary   \n",
            "20799                              David Swanson   \n",
            "\n",
            "                                                    text  \\\n",
            "0      House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
            "1      Ever get the feeling your life circles the rou...   \n",
            "2      Why the Truth Might Get You Fired October 29, ...   \n",
            "3      Videos 15 Civilians Killed In Single US Airstr...   \n",
            "4      Print \\nAn Iranian woman has been sentenced to...   \n",
            "...                                                  ...   \n",
            "20795  Rapper T. I. unloaded on black celebrities who...   \n",
            "20796  When the Green Bay Packers lost to the Washing...   \n",
            "20797  The Macy’s of today grew from the union of sev...   \n",
            "20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
            "20799    David Swanson is an author, activist, journa...   \n",
            "\n",
            "                                                 content  \n",
            "0      Darrell Lucus House Dem Aide: We Didn’t Even S...  \n",
            "1      Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...  \n",
            "2      Consortiumnews.com Why the Truth Might Get You...  \n",
            "3      Jessica Purkiss 15 Civilians Killed In Single ...  \n",
            "4      Howard Portnoy Iranian woman jailed for fictio...  \n",
            "...                                                  ...  \n",
            "20795  Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...  \n",
            "20796  Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...  \n",
            "20797  Michael J. de la Merced and Rachel Abrams Macy...  \n",
            "20798  Alex Ansary NATO, Russia To Hold Parallel Exer...  \n",
            "20799            David Swanson What Keeps the F-35 Alive  \n",
            "\n",
            "[20800 rows x 5 columns]\n",
            "0        1\n",
            "1        0\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "        ..\n",
            "20795    0\n",
            "20796    0\n",
            "20797    0\n",
            "20798    1\n",
            "20799    1\n",
            "Name: label, Length: 20800, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**stemming:**\n",
        "\n",
        "stemming is the process of reducing a word to its root word - removes prefixs and suffixes \n",
        "\n",
        "e.g - actor, actress, acting --> act\n",
        "\n",
        "(helps with better performance in model)\n",
        "\n",
        "- after we vectorize, convert words to feature vectors = numerical data, then we can feed it to ml model"
      ],
      "metadata": {
        "id": "htmgyJQsNdeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem = PorterStemmer()"
      ],
      "metadata": {
        "id": "1j9LMFLKN1N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def = define to create a function : name of function is stemming\n",
        "def stemming (content):\n",
        "  # regular expression library, searching text. sub, substitues certain values. \"^\" excludes certain things \"\n",
        "  # we just want alpehet words, to exclude everything that isnt present in our set (unesscary stuff: numbers, puncuation)\n",
        "  # feed content column to stemming, to remove other stuf exepct regular letters/alpehebet \n",
        "  # content = title + author data together\n",
        "  stemmed_content = re.sub('[^a-zA-Z]',' ', content)\n",
        "  # make everything lowercase letts to make it easier\n",
        "  stemmed_content = stemmed_content.lower()\n",
        "  # splitted to respective lists, converted to lists\n",
        "  stemmed_content = stemmed_content.split()\n",
        "  # stemming function to each word. and reducing it to its root word to all the words. remove all stopwords (which is insignficiant words) which is kinda useless in our dataset \n",
        "  # all words EXECPT stopwords, stem them to root form\n",
        "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  #then just join all of the words\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "  return stemmed_content \n",
        "\n",
        "  # 1) first create function called stemming, content is input were giving\n",
        "  "
      ],
      "metadata": {
        "id": "eNotsW1iNPrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset['content'] = news_dataset['content'].apply(stemming)\n",
        "#taking content colum (author+title) to do procces of all stemming fucntion. to put in in same coluns as the data frame"
      ],
      "metadata": {
        "id": "d0LtLdWQOClh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all insignifnicant words will be removed from stemming procress "
      ],
      "metadata": {
        "id": "Rh6AZapSQkD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using text will take a long time for proccesing but the author and title work just fine\n",
        "X = news_dataset['content'].values \n",
        "Y = news_dataset['label'].values"
      ],
      "metadata": {
        "id": "upToXJ-ARQnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X) # this is our data, there are alot of values \"...\" = alot of values\n",
        "#this is what we will feed our model"
      ],
      "metadata": {
        "id": "dhTip75dRk9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e708a7b7-e400-4dd9-b825-a77c14613440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['darrel lucu hous dem aid even see comey letter jason chaffetz tweet'\n",
            " 'daniel j flynn flynn hillari clinton big woman campu breitbart'\n",
            " 'consortiumnew com truth might get fire' ...\n",
            " 'michael j de la merc rachel abram maci said receiv takeov approach hudson bay new york time'\n",
            " 'alex ansari nato russia hold parallel exercis balkan'\n",
            " 'david swanson keep f aliv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y) # labels "
      ],
      "metadata": {
        "id": "zWSaQ4itRsqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2befd8e6-271a-4fe2-d896-e13c7b25922b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape #w e have 20800 labels "
      ],
      "metadata": {
        "id": "XVYDrkKgRzR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da0eada-2817-4b04-bc9e-76679f2b6a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computers wont understand ^^^ so we have to vectorize all of the text"
      ],
      "metadata": {
        "id": "BKvD-lSuR5SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the textual data to numerical data\n",
        "#tf = term freqieunces. idf = inverse document frequency\n",
        "  # counts how many times a word is repeated in a dataset\n",
        "    # --> it shows how important it is\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(X)\n",
        "\n",
        "X = vectorizer.transform(X)"
      ],
      "metadata": {
        "id": "rqEiHfgSSFal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "# now it has converted the text from above to numbres"
      ],
      "metadata": {
        "id": "m05SpDFwSqxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe2f025-587a-4984-c3aa-0e6d21a58a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 15686)\t0.28485063562728646\n",
            "  (0, 13473)\t0.2565896679337957\n",
            "  (0, 8909)\t0.3635963806326075\n",
            "  (0, 8630)\t0.29212514087043684\n",
            "  (0, 7692)\t0.24785219520671603\n",
            "  (0, 7005)\t0.21874169089359144\n",
            "  (0, 4973)\t0.233316966909351\n",
            "  (0, 3792)\t0.2705332480845492\n",
            "  (0, 3600)\t0.3598939188262559\n",
            "  (0, 2959)\t0.2468450128533713\n",
            "  (0, 2483)\t0.3676519686797209\n",
            "  (0, 267)\t0.27010124977708766\n",
            "  (1, 16799)\t0.30071745655510157\n",
            "  (1, 6816)\t0.1904660198296849\n",
            "  (1, 5503)\t0.7143299355715573\n",
            "  (1, 3568)\t0.26373768806048464\n",
            "  (1, 2813)\t0.19094574062359204\n",
            "  (1, 2223)\t0.3827320386859759\n",
            "  (1, 1894)\t0.15521974226349364\n",
            "  (1, 1497)\t0.2939891562094648\n",
            "  (2, 15611)\t0.41544962664721613\n",
            "  (2, 9620)\t0.49351492943649944\n",
            "  (2, 5968)\t0.3474613386728292\n",
            "  (2, 5389)\t0.3866530551182615\n",
            "  (2, 3103)\t0.46097489583229645\n",
            "  :\t:\n",
            "  (20797, 13122)\t0.2482526352197606\n",
            "  (20797, 12344)\t0.27263457663336677\n",
            "  (20797, 12138)\t0.24778257724396507\n",
            "  (20797, 10306)\t0.08038079000566466\n",
            "  (20797, 9588)\t0.174553480255222\n",
            "  (20797, 9518)\t0.2954204003420313\n",
            "  (20797, 8988)\t0.36160868928090795\n",
            "  (20797, 8364)\t0.22322585870464118\n",
            "  (20797, 7042)\t0.21799048897828688\n",
            "  (20797, 3643)\t0.21155500613623743\n",
            "  (20797, 1287)\t0.33538056804139865\n",
            "  (20797, 699)\t0.30685846079762347\n",
            "  (20797, 43)\t0.29710241860700626\n",
            "  (20798, 13046)\t0.22363267488270608\n",
            "  (20798, 11052)\t0.4460515589182236\n",
            "  (20798, 10177)\t0.3192496370187028\n",
            "  (20798, 6889)\t0.32496285694299426\n",
            "  (20798, 5032)\t0.4083701450239529\n",
            "  (20798, 1125)\t0.4460515589182236\n",
            "  (20798, 588)\t0.3112141524638974\n",
            "  (20798, 350)\t0.28446937819072576\n",
            "  (20799, 14852)\t0.5677577267055112\n",
            "  (20799, 8036)\t0.45983893273780013\n",
            "  (20799, 3623)\t0.37927626273066584\n",
            "  (20799, 377)\t0.5677577267055112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting the dataset to training and test data"
      ],
      "metadata": {
        "id": "bYJRHTeATSPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=2)\n",
        "# splitting data into data strains, traininng and testing data\n",
        "  # 80% should be training, 20% should be testing - thats why we mentioe 0.2 for testing size\n",
        "  # lables for X is stored in Y...\n",
        "  # stratify means that the fake news and real news needs to be split\n",
        "  #randomstate=2 is to split it into 2 ro reporduce a specifc code "
      ],
      "metadata": {
        "id": "0fpXa30ETUnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training the model: logistic regression"
      ],
      "metadata": {
        "id": "B8Q3Aq79UJhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "OlL9X-yRTpUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "w3rGB7rVUQJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae5fe51-dbfb-4802-fa52-ecdb222ccc69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation"
      ],
      "metadata": {
        "id": "33DI5HEoUmve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score on the test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
      ],
      "metadata": {
        "id": "2VS9n5dXUhgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score of the test data : ', test_data_accuracy)"
      ],
      "metadata": {
        "id": "YOghXqwHUuSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e9aa25-71c9-45cb-d010-4b070dde8299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the test data :  0.9790865384615385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[4]\n",
        "\n",
        "prediction = model.predict(X_new)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0]==0):\n",
        "  print('The news is Real')\n",
        "else:\n",
        "  print('The news is Fake')"
      ],
      "metadata": {
        "id": "l9M_JW6JVO3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280f0181-cc6c-4f42-b430-abd4777364b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "The news is Real\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "making a predctive system"
      ],
      "metadata": {
        "id": "o7O5ToOoVQMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test[10])"
      ],
      "metadata": {
        "id": "ZMkChHaqVSnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07d8ea4-c6d3-42bc-820a-3415e1fce3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPCr4vRtVWWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}